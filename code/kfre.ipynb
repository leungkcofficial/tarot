{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "# from pandas.testing import assert_frame_equal\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import gc, json, os, tempfile\n",
    "import dataloader, databalancer, datatrainer, modeleval\n",
    "importlib.reload(dataloader)\n",
    "importlib.reload(databalancer)\n",
    "importlib.reload(datatrainer)\n",
    "importlib.reload(modeleval)\n",
    "from dataloader import read_imputed_datasets_hdf5, load_and_transform_data, prep_tensor\n",
    "from databalancer import df_event_focus, rebalance_data\n",
    "from datatrainer import recursive_clustering\n",
    "from modeleval import test_model, nam_dagostino_chi2, get_baseline_hazard_at_timepoints, calculate_null_brier\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.utils import resample\n",
    "from lifelines import KaplanMeierFitter, AalenJohansenFitter, CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from pycox.evaluation import EvalSurv\n",
    "from scipy.stats import chi2, norm\n",
    "import psutil \n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load constants and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 12345\n",
    "feature_col = ['gender', 'dm', 'ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3']\n",
    "duration_col = ['date_from_sub_60']\n",
    "event_col = ['endpoint']\n",
    "cluster_col = ['key']\n",
    "\n",
    "# Define your feature groups\n",
    "cat_features = ['gender', 'dm', 'ht', 'sprint']\n",
    "log_features = ['a1c', 'po4', 'UACR_mg_g', 'Cr']\n",
    "standard_features = ['age', 'alb', 'ca', 'hb', 'hco3']\n",
    "passthrough_features = ['key', 'date_from_sub_60', 'endpoint']\n",
    "\n",
    "base_filename = '/mnt/d/pydatascience/g3_regress/data/X/X_20240628'\n",
    "X_load = read_imputed_datasets_hdf5(base_filename)\n",
    "test_df = X_load['X_test_main'][0]\n",
    "test_df = df_event_focus(df=test_df, event_col=event_col, event_focus=1)\n",
    "X_test = test_df[feature_col].copy()\n",
    "y_test = test_df[duration_col + event_col].copy()\n",
    "\n",
    "# Impute X_test:\n",
    "if X_test.isnull().values.any():\n",
    "    imputer = IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=RANDOM_SEED,\n",
    "                                initial_strategy='mean', n_nearest_features=None, min_value=1e-6,\n",
    "                                imputation_order='ascending')\n",
    "    X_test = pd.DataFrame(imputer.fit_transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "# Constants based on gender\n",
    "X_test['Cr_mg_dL'] = X_test['Cr'] / 88.4\n",
    "conditions = [\n",
    "    X_test['gender'] == 0,  # Female\n",
    "    X_test['gender'] == 1   # Male\n",
    "]\n",
    "\n",
    "choices_k = [0.7, 0.9]  # kappa values for female and male\n",
    "choices_alpha = [-0.241, -0.302]  # alpha values for female and male\n",
    "X_test['kappa'] = np.select(conditions, choices_k, default=np.nan)\n",
    "X_test['alpha'] = np.select(conditions, choices_alpha, default=np.nan)\n",
    "\n",
    "# Calculate eGFR using the CKD-EPI 2021 equation\n",
    "X_test['eGFR'] = 142 * (X_test['Cr_mg_dL'] / X_test['kappa']).clip(upper=1)**X_test['alpha'] * \\\n",
    "                        (X_test['Cr_mg_dL'] / X_test['kappa']).clip(lower=1)**(-1.2) * \\\n",
    "                        0.9938**X_test['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Code the KFRE\n",
    "- Tangri N, Grams ME, Levey AS, Coresh J, Appel LJ, Astor BC, et al. Multinational Assessment of Accuracy of Equations for Predicting Risk of Kidney Failure: A Meta-analysis. JAMA. 2016;315(2): 164–174. https://doi.org/10.1001/jama.2015.18202.\n",
    "\n",
    "#### 4-variable 2-yr calibrated non-American equation\n",
    "- 1 - 0.9832^exp(-0.2201 x (age/10 – 7.036) + 0.2467 x (male – 0.5642) – 0.5567 x (eGFR/5 – 7.222) + 0.4510 x (logACR – 5.137))\n",
    "#### 8-variable 2-yr calibrated non-American equation\n",
    "- 1 – 0.9827 ^ exp (-0.1992 × (age/10 – 7.036) + 0.1602 × (male – 0.5642) – 0.4919 × (eGFR/5 – 7.222) + 0.3364 × (logACR – 5.137) – 0.3441 × (albumin – 3.997) + 0.2604 × (phosphorous – 3.916) – 0.07354 × (bicarbonate – 25.57) – 0.2228 × (calcium – 9.355))\n",
    "#### 4-variable 5-yr calibrated non-American equation\n",
    "- 1 – 0.9365 ^ exp (-0.2201 × (age/10 – 7.036) + 0.2467 × (male – 0.5642) – 0.5567 × (eGFR/5 – 7.222) + 0.4510 × (logACR – 5.137))\n",
    "#### 8-variable 5-yr calibrated non-American equation\n",
    "- 1 – 0.9245 ^ exp (-0.1992 × (age/10 – 7.036) + 0.1602 × (male – 0.5642) – 0.4919 × (eGFR/5 – 7.222) + 0.3364 × (logACR – 5.137) – 0.3441 × (albumin – 3.997) + 0.2604 × (phosphorous – 3.916) – 0.07354 × (bicarbonate – 25.57) – 0.2228 × (calcium – 9.355))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define risk calculation functions\n",
    "def calculate_4_variable_2yr_risk(row):\n",
    "    return 1 - 0.9832**np.exp(-0.2201 * (row['age'] / 10 - 7.036) + \n",
    "                              0.2467 * (row['gender'] - 0.5642) - \n",
    "                              0.5567 * (row['eGFR'] / 5 - 7.222) + \n",
    "                              0.4510 * (np.log(row['UACR_mg_g']) - 5.137))\n",
    "\n",
    "def calculate_8_variable_2yr_risk(row):\n",
    "    return 1 - 0.9827**np.exp(-0.1992 * (row['age'] / 10 - 7.036) + \n",
    "                              0.1602 * (row['gender'] - 0.5642) - \n",
    "                              0.4919 * (row['eGFR'] / 5 - 7.222) + \n",
    "                              0.3364 * (np.log(row['UACR_mg_g']) - 5.137) - \n",
    "                              0.3441 * (row['alb'] - 3.997) + \n",
    "                              0.2604 * (row['po4'] - 3.916) - \n",
    "                              0.07354 * (row['hco3'] - 25.57) - \n",
    "                              0.2228 * (row['ca'] - 9.355))\n",
    "\n",
    "def calculate_4_variable_5yr_risk(row):\n",
    "    return 1 - 0.9365**np.exp(-0.2201 * (row['age'] / 10 - 7.036) + \n",
    "                              0.2467 * (row['gender'] - 0.5642) - \n",
    "                              0.5567 * (row['eGFR'] / 5 - 7.222) + \n",
    "                              0.4510 * (np.log(row['UACR_mg_g']) - 5.137))\n",
    "\n",
    "def calculate_8_variable_5yr_risk(row):\n",
    "    return 1 - 0.9245**np.exp(-0.1992 * (row['age'] / 10 - 7.036) + \n",
    "                              0.1602 * (row['gender'] - 0.5642) - \n",
    "                              0.4919 * (row['eGFR'] / 5 - 7.222) + \n",
    "                              0.3364 * (np.log(row['UACR_mg_g']) - 5.137) - \n",
    "                              0.3441 * (row['alb'] - 3.997) + \n",
    "                              0.2604 * (row['po4'] - 3.916) - \n",
    "                              0.07354 * (row['hco3'] - 25.57) - \n",
    "                              0.2228 * (row['ca'] - 9.355))\n",
    "    \n",
    "pred_df = pd.DataFrame(index=X_test.index)\n",
    "pred_df['4v2y'] = X_test.apply(calculate_4_variable_2yr_risk, axis=1) \n",
    "pred_df['8v2y'] = X_test.apply(calculate_8_variable_2yr_risk, axis=1) \n",
    "pred_df['4v5y'] = X_test.apply(calculate_4_variable_5yr_risk, axis=1) \n",
    "pred_df['8v5y'] = X_test.apply(calculate_8_variable_5yr_risk, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 730 - Column: 4v2y - Chi-squared Statistic: 0.42486800178123685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 730 - Column: 8v2y - Chi-squared Statistic: 16.173095483953407\n",
      "Time: 730 - Column: 4v5y - Chi-squared Statistic: 0.9324427115011152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 730 - Column: 8v5y - Chi-squared Statistic: 3.563891893655296\n",
      "Time: 1825 - Column: 4v2y - Chi-squared Statistic: 0.8282271238579535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1825 - Column: 8v2y - Chi-squared Statistic: 752154.1133617164\n",
      "Time: 1825 - Column: 4v5y - Chi-squared Statistic: 0.2999812160308805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goma/miniconda3/envs/ai_dev/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 1825 - Column: 8v5y - Chi-squared Statistic: 167207.0244822644\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for time in np.array([2*365, 5*365]):\n",
    "    for c in pred_df.columns:\n",
    "        prob_df = pd.DataFrame({\n",
    "            'predicted_probs': pred_df[c].values,\n",
    "            'observed_probs': np.nan  # Placeholder for observed probabilities\n",
    "        }, index=y_test.index)\n",
    "        prob_df['quantile'] = pd.qcut(prob_df['predicted_probs'], 5, labels=False, duplicates='drop')\n",
    "        prob_df['quantile'] = prob_df['quantile'].astype(int)\n",
    "        # Calculate observed probabilities for each quintile using Aalen-Johansen estimator\n",
    "        observed_probs = []\n",
    "        for q in prob_df['quantile'].unique():\n",
    "            mask = prob_df['quantile'] == q\n",
    "            durations = pd.Series(y_test.loc[mask, duration_col[0]].values.ravel(), index=y_test.loc[mask, duration_col[0]].index).astype(float)\n",
    "            event_observed = pd.Series(y_test.loc[mask, event_col[0]].values.ravel(), index=y_test.loc[mask, event_col[0]].index)\n",
    "            ajf = AalenJohansenFitter()\n",
    "            ajf.fit(durations=durations, event_observed=event_observed, event_of_interest=1)\n",
    "            # Find the closest time point if `time` is not in the index\n",
    "            if time not in ajf.cumulative_density_.index:\n",
    "                closest_idx = ajf.cumulative_density_.index.get_indexer([time], method='nearest')[0]\n",
    "                closest_time = ajf.cumulative_density_.index[closest_idx]\n",
    "            else:\n",
    "                closest_time = time\n",
    "            observed_probs.append(ajf.cumulative_density_.loc[closest_time].values[0])\n",
    "        # Map observed probabilities back to the DataFrame\n",
    "        prob_df['observed_probs'] = prob_df['quantile'].map(dict(zip(prob_df['quantile'].unique(), observed_probs)))\n",
    "        grouped = prob_df.groupby('quantile')\n",
    "        observed_events = grouped['observed_probs'].mean()\n",
    "        expected_events = grouped['predicted_probs'].mean()\n",
    "        # mean_p_g = grouped['predicted_probs'].mean()\n",
    "        n = grouped.size()\n",
    "            \n",
    "        # chi2_stat = np.sum(((observed_events - expected_events) ** 2) / (n * mean_p_g * (1 - mean_p_g)))\n",
    "        chi2_stat = np.sum(((observed_events - expected_events) ** 2) / (expected_events * (1 - expected_events/ n)))\n",
    "        dof = len(n) - 2\n",
    "        # Calculate p-value\n",
    "        p_value = 1 - chi2.cdf(chi2_stat, dof)\n",
    "        print(f'Time: {time} - Column: {c} - Chi-squared Statistic: {chi2_stat}')\n",
    "        \n",
    "        # Calculate Brier score\n",
    "        brier_score = brier_score_loss(y_test[event_col[0]], prob_df['predicted_probs'])\n",
    "\n",
    "        # Calculate Concordance Index (C-index)\n",
    "        c_index = concordance_index(y_test[duration_col[0]], -prob_df['predicted_probs'], y_test[event_col[0]])\n",
    "\n",
    "        # Store the result\n",
    "        results.append({\n",
    "            'time': time,\n",
    "            'column': c,\n",
    "            'observed_events': observed_events,\n",
    "            'expected events': expected_events,\n",
    "            'chi2_stat': chi2_stat,\n",
    "            'p-value': p_value,\n",
    "            'brier_score': brier_score,\n",
    "            'c_index': c_index\n",
    "        })\n",
    "        \n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>column</th>\n",
       "      <th>observed_events</th>\n",
       "      <th>expected events</th>\n",
       "      <th>chi2_stat</th>\n",
       "      <th>p-value</th>\n",
       "      <th>brier_score</th>\n",
       "      <th>c_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>4v2y</td>\n",
       "      <td>quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...</td>\n",
       "      <td>quantile\n",
       "0    0.000131\n",
       "1    0.001985\n",
       "2    0.00...</td>\n",
       "      <td>0.424868</td>\n",
       "      <td>0.935059</td>\n",
       "      <td>0.048474</td>\n",
       "      <td>0.969887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>730</td>\n",
       "      <td>8v2y</td>\n",
       "      <td>quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...</td>\n",
       "      <td>quantile\n",
       "0    1.730431e-09\n",
       "1    2.734300e-08\n",
       "2...</td>\n",
       "      <td>16.173095</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.916222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>4v5y</td>\n",
       "      <td>quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...</td>\n",
       "      <td>quantile\n",
       "0    0.000505\n",
       "1    0.007659\n",
       "2    0.03...</td>\n",
       "      <td>0.932443</td>\n",
       "      <td>0.817592</td>\n",
       "      <td>0.131479</td>\n",
       "      <td>0.969887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>730</td>\n",
       "      <td>8v5y</td>\n",
       "      <td>quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...</td>\n",
       "      <td>quantile\n",
       "0    7.784059e-09\n",
       "1    1.229980e-07\n",
       "2...</td>\n",
       "      <td>3.563892</td>\n",
       "      <td>0.312570</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.916222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1825</td>\n",
       "      <td>4v2y</td>\n",
       "      <td>quantile\n",
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4...</td>\n",
       "      <td>quantile\n",
       "0    0.000131\n",
       "1    0.001985\n",
       "2    0.00...</td>\n",
       "      <td>0.828227</td>\n",
       "      <td>0.842704</td>\n",
       "      <td>0.048474</td>\n",
       "      <td>0.969887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1825</td>\n",
       "      <td>8v2y</td>\n",
       "      <td>quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...</td>\n",
       "      <td>quantile\n",
       "0    1.730431e-09\n",
       "1    2.734300e-08\n",
       "2...</td>\n",
       "      <td>752154.113362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.916222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1825</td>\n",
       "      <td>4v5y</td>\n",
       "      <td>quantile\n",
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4...</td>\n",
       "      <td>quantile\n",
       "0    0.000505\n",
       "1    0.007659\n",
       "2    0.03...</td>\n",
       "      <td>0.299981</td>\n",
       "      <td>0.960032</td>\n",
       "      <td>0.131479</td>\n",
       "      <td>0.969887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1825</td>\n",
       "      <td>8v5y</td>\n",
       "      <td>quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...</td>\n",
       "      <td>quantile\n",
       "0    7.784059e-09\n",
       "1    1.229980e-07\n",
       "2...</td>\n",
       "      <td>167207.024482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.916222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time column                                    observed_events  \\\n",
       "0   730   4v2y  quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...   \n",
       "1   730   8v2y  quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...   \n",
       "2   730   4v5y  quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...   \n",
       "3   730   8v5y  quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...   \n",
       "4  1825   4v2y  quantile\n",
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4...   \n",
       "5  1825   8v2y  quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...   \n",
       "6  1825   4v5y  quantile\n",
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4...   \n",
       "7  1825   8v5y  quantile\n",
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.00...   \n",
       "\n",
       "                                     expected events      chi2_stat   p-value  \\\n",
       "0  quantile\n",
       "0    0.000131\n",
       "1    0.001985\n",
       "2    0.00...       0.424868  0.935059   \n",
       "1  quantile\n",
       "0    1.730431e-09\n",
       "1    2.734300e-08\n",
       "2...      16.173095  0.001045   \n",
       "2  quantile\n",
       "0    0.000505\n",
       "1    0.007659\n",
       "2    0.03...       0.932443  0.817592   \n",
       "3  quantile\n",
       "0    7.784059e-09\n",
       "1    1.229980e-07\n",
       "2...       3.563892  0.312570   \n",
       "4  quantile\n",
       "0    0.000131\n",
       "1    0.001985\n",
       "2    0.00...       0.828227  0.842704   \n",
       "5  quantile\n",
       "0    1.730431e-09\n",
       "1    2.734300e-08\n",
       "2...  752154.113362  0.000000   \n",
       "6  quantile\n",
       "0    0.000505\n",
       "1    0.007659\n",
       "2    0.03...       0.299981  0.960032   \n",
       "7  quantile\n",
       "0    7.784059e-09\n",
       "1    1.229980e-07\n",
       "2...  167207.024482  0.000000   \n",
       "\n",
       "   brier_score   c_index  \n",
       "0     0.048474  0.969887  \n",
       "1     0.004935  0.916222  \n",
       "2     0.131479  0.969887  \n",
       "3     0.004960  0.916222  \n",
       "4     0.048474  0.969887  \n",
       "5     0.004935  0.916222  \n",
       "6     0.131479  0.969887  \n",
       "7     0.004960  0.916222  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_json('/mnt/d/pydatascience/g3_regress/data/results/kfre.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bootstrap 500 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_null_brier(durations, events, time_grid, event_of_interest=1):\n",
    "    \"\"\"\n",
    "    Calculate the null model Brier score for a given set of durations and events.\n",
    "\n",
    "    Args:\n",
    "        durations (array-like): Event/censoring times.\n",
    "        events (array-like): Event indicators (1 for event, 0 for censoring).\n",
    "        time_grid (list): List of time points for evaluation.\n",
    "        event_of_interest (int): The event type of interest for competing risks.\n",
    "\n",
    "    Returns:\n",
    "        float: Integrated Brier score for the null model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def interpolate_cif(cif, time_points):\n",
    "        cif_values = cif.values.squeeze()\n",
    "        cif_index = cif.index.values\n",
    "        max_time = cif_index[-1]\n",
    "        max_cif_value = cif_values[-1]\n",
    "        \n",
    "        # Interpolation within range\n",
    "        interpolated = np.interp(time_points, cif_index, cif_values)\n",
    "        \n",
    "        # Handle extrapolation for times > max_time\n",
    "        interpolated[time_points > max_time] = max_cif_value\n",
    "        \n",
    "        return interpolated\n",
    "    # Ensure durations and events are NumPy arrays\n",
    "    durations = durations.squeeze()\n",
    "    events = events.squeeze()\n",
    "\n",
    "    # Resolve ties in event times by adding small noise\n",
    "    unique_durations, counts = np.unique(durations, return_counts=True)\n",
    "    tied_indices = np.isin(durations, unique_durations[counts > 1])\n",
    "    noise = np.random.uniform(low=-1e-6, high=1e-6, size=len(durations))\n",
    "    durations[tied_indices] += noise[tied_indices]\n",
    "\n",
    "    # Fit Aalen-Johansen estimator\n",
    "    ajf = AalenJohansenFitter()\n",
    "    ajf.fit(durations, events, event_of_interest=event_of_interest)\n",
    "    cif = ajf.cumulative_density_\n",
    "\n",
    "    # Calculate survival probabilities\n",
    "    surv_probs = 1 - interpolate_cif(cif, time_grid) \n",
    "\n",
    "    # Create survival probability DataFrame for EvalSurv\n",
    "    surv_df = pd.DataFrame(\n",
    "        np.tile(surv_probs, (len(durations), 1)).T, index=time_grid\n",
    "    )\n",
    "\n",
    "    # Evaluate using EvalSurv\n",
    "    ev = EvalSurv(surv_df, durations, events == event_of_interest, censor_surv=\"km\")\n",
    "\n",
    "    # Integrated Brier score\n",
    "    integrated_brier = ev.integrated_brier_score(time_grid)\n",
    "    return integrated_brier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4505994501343505"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def interpolate_cif(cif, time_points):\n",
    "    cif_values = cif.values.squeeze()\n",
    "    cif_index = cif.index.values\n",
    "    max_time = cif_index[-1]\n",
    "    max_cif_value = cif_values[-1]\n",
    "    \n",
    "    # Interpolation within range\n",
    "    interpolated = np.interp(time_points, cif_index, cif_values)\n",
    "    \n",
    "    # Handle extrapolation for times > max_time\n",
    "    interpolated[time_points > max_time] = max_cif_value\n",
    "    \n",
    "    return interpolated\n",
    "\n",
    "ex_durations = y_test_bootstrap[duration_col].values.squeeze()\n",
    "ex_events = y_test_bootstrap[event_col].values.squeeze()\n",
    "ajf = AalenJohansenFitter()\n",
    "ajf.fit(ex_durations, ex_events, event_of_interest=1)\n",
    "cif = ajf.cumulative_density_\n",
    "time_points = np.array([2 * 365, 5 * 365])\n",
    "surv_probs = 1 - interpolate_cif(cif, time_points)\n",
    "\n",
    "surv_df = pd.DataFrame(\n",
    "        np.tile(surv_probs, (len(ex_durations), 1)).T, index=time_points)\n",
    "ev = EvalSurv(surv_df, ex_durations, ex_events == 1, censor_surv=\"km\")\n",
    "ev.integrated_brier_score(time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage for bootstrapped results\n",
    "bootstrap_results = []\n",
    "\n",
    "# Number of bootstraps\n",
    "n_bootstraps = 500\n",
    "\n",
    "for i in range(n_bootstraps):\n",
    "    # Resample with replacement\n",
    "    X_test_bootstrap = X_test[X_test.index.isin(resample(X_test.index))]\n",
    "    y_test_bootstrap = y_test.iloc[X_test_bootstrap.index,:]\n",
    "    \n",
    "    # Calculate KFRE risks\n",
    "    pred_df = pd.DataFrame(index=X_test_bootstrap.index)\n",
    "    pred_df['4v2y'] = X_test_bootstrap.apply(calculate_4_variable_2yr_risk, axis=1)\n",
    "    pred_df['8v2y'] = X_test_bootstrap.apply(calculate_8_variable_2yr_risk, axis=1)\n",
    "    pred_df['4v5y'] = X_test_bootstrap.apply(calculate_4_variable_5yr_risk, axis=1)\n",
    "    pred_df['8v5y'] = X_test_bootstrap.apply(calculate_8_variable_5yr_risk, axis=1)\n",
    "    \n",
    "# Calculate null Brier scores for each time grid\n",
    "    null_brier_scores = {}\n",
    "    for t in np.array([2* 365, 5 * 365]):\n",
    "        null_brier_scores[t] = calculate_null_brier(\n",
    "            y_test_bootstrap[duration_col].values,\n",
    "            y_test_bootstrap[event_col].values,\n",
    "            np.array([t])\n",
    "        )    \n",
    "    \n",
    "    for time in np.array([2 * 365, 5 * 365]):\n",
    "        for c in pred_df.columns:\n",
    "            prob_df = pd.DataFrame({\n",
    "                'predicted_probs': pred_df[c].values,\n",
    "                'observed_probs': np.nan  # Placeholder for observed probabilities\n",
    "            }, index=y_test_bootstrap.index)\n",
    "            prob_df['quantile'] = pd.qcut(prob_df['predicted_probs'], 5, labels=False, duplicates='drop')\n",
    "            prob_df['quantile'] = prob_df['quantile'].astype(int)\n",
    "            \n",
    "            observed_probs = []\n",
    "            for q in prob_df['quantile'].unique():\n",
    "                mask = prob_df['quantile'] == q\n",
    "                durations = y_test_bootstrap.loc[mask, duration_col[0]].astype(float)\n",
    "                event_observed = event_observed = y_test_bootstrap.loc[mask, event_col[0]]\n",
    "                ajf = AalenJohansenFitter()\n",
    "                ajf.fit(durations=durations, event_observed=event_observed, event_of_interest=1)\n",
    "                # Find the closest time point if `time` is not in the index\n",
    "                if time not in ajf.cumulative_density_.index:\n",
    "                    closest_idx = ajf.cumulative_density_.index.get_indexer([time], method='nearest')[0]\n",
    "                    closest_time = ajf.cumulative_density_.index[closest_idx]\n",
    "                else:\n",
    "                    closest_time = time\n",
    "                observed_probs.append(ajf.cumulative_density_.loc[closest_time].values[0])\n",
    "            \n",
    "            prob_df['observed_probs'] = prob_df['quantile'].map(dict(zip(prob_df['quantile'].unique(), observed_probs)))\n",
    "            grouped = prob_df.groupby('quantile')\n",
    "            observed_events = grouped['observed_probs'].mean()\n",
    "            expected_events = grouped['predicted_probs'].mean()\n",
    "            n = grouped.size()\n",
    "            \n",
    "            chi2_stat = np.sum(((observed_events - expected_events) ** 2) / (expected_events * (1 - expected_events / n)))\n",
    "            dof = len(n) - 2\n",
    "            p_value = 1 - chi2.cdf(chi2_stat, dof)\n",
    "            brier_score = brier_score_loss(y_test_bootstrap[event_col[0]], prob_df['predicted_probs'])\n",
    "            c_index = concordance_index(y_test_bootstrap[duration_col[0]], -prob_df['predicted_probs'], y_test_bootstrap[event_col[0]])\n",
    "            \n",
    "            # Store bootstrap result\n",
    "            bootstrap_results.append({\n",
    "                'time': time,\n",
    "                'column': c,\n",
    "                'brier_score': brier_score,\n",
    "                'c_index': c_index,\n",
    "                'chi2_stat': chi2_stat,\n",
    "                'p_value': p_value,\n",
    "                'null_brier_score': null_brier_scores[time]\n",
    "            })\n",
    "\n",
    "# Convert bootstrap results to DataFrame\n",
    "bootstrap_df = pd.DataFrame(bootstrap_results)\n",
    "\n",
    "# Aggregate metrics\n",
    "summary = bootstrap_df.groupby(['time', 'column']).agg(\n",
    "    mean_brier=('brier_score', 'mean'),\n",
    "    ci_lower_brier=('brier_score', lambda x: np.percentile(x, 2.5)),\n",
    "    ci_upper_brier=('brier_score', lambda x: np.percentile(x, 97.5)),\n",
    "    mean_c_index=('c_index', 'mean'),\n",
    "    ci_lower_c_index=('c_index', lambda x: np.percentile(x, 2.5)),\n",
    "    ci_upper_c_index=('c_index', lambda x: np.percentile(x, 97.5)),\n",
    "    mean_chi2=('chi2_stat', 'mean'),\n",
    "    mean_p_value=('p_value', 'mean')\n",
    ").reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = summary.loc[[0,2,5,7], :]\n",
    "final_df.to_json('/mnt/d/pydatascience/g3_regress/data/results/kfre_bootstrap.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

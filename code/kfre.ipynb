{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "# from pandas.testing import assert_frame_equal\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import gc, json, os, tempfile\n",
    "import dataloader, databalancer, datatrainer, modeleval\n",
    "importlib.reload(dataloader)\n",
    "importlib.reload(databalancer)\n",
    "importlib.reload(datatrainer)\n",
    "importlib.reload(modeleval)\n",
    "from dataloader import read_imputed_datasets_hdf5, load_and_transform_data, prep_tensor\n",
    "from databalancer import df_event_focus, rebalance_data\n",
    "from datatrainer import recursive_clustering\n",
    "from modeleval import test_model, nam_dagostino_chi2, get_baseline_hazard_at_timepoints, calculate_null_brier\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.utils import resample\n",
    "from lifelines import KaplanMeierFitter, AalenJohansenFitter, CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from pycox.evaluation import EvalSurv\n",
    "from scipy.stats import chi2, norm\n",
    "import psutil \n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load constants and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 12345\n",
    "feature_col = ['gender', 'dm', 'ht', 'sprint', 'a1c', 'po4', 'UACR_mg_g', 'Cr', 'age', 'alb', 'ca', 'hb', 'hco3']\n",
    "duration_col = ['date_from_sub_60']\n",
    "event_col = ['endpoint']\n",
    "cluster_col = ['key']\n",
    "\n",
    "# Define your feature groups\n",
    "cat_features = ['gender', 'dm', 'ht', 'sprint']\n",
    "log_features = ['a1c', 'po4', 'UACR_mg_g', 'Cr']\n",
    "standard_features = ['age', 'alb', 'ca', 'hb', 'hco3']\n",
    "passthrough_features = ['key', 'date_from_sub_60', 'endpoint']\n",
    "\n",
    "base_filename = '/mnt/d/pydatascience/g3_regress/data/X/X_20240628'\n",
    "X_load = read_imputed_datasets_hdf5(base_filename)\n",
    "test_df = X_load['X_test_main'][0]\n",
    "test_df = df_event_focus(df=test_df, event_col=event_col, event_focus=1)\n",
    "X_test = test_df[feature_col].copy()\n",
    "y_test = test_df[duration_col + event_col].copy()\n",
    "\n",
    "# Impute X_test:\n",
    "if X_test.isnull().values.any():\n",
    "    imputer = IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=RANDOM_SEED,\n",
    "                                initial_strategy='mean', n_nearest_features=None, min_value=1e-6,\n",
    "                                imputation_order='ascending')\n",
    "    X_test = pd.DataFrame(imputer.fit_transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "# Constants based on gender\n",
    "X_test['Cr_mg_dL'] = X_test['Cr'] / 88.4\n",
    "conditions = [\n",
    "    X_test['gender'] == 0,  # Female\n",
    "    X_test['gender'] == 1   # Male\n",
    "]\n",
    "\n",
    "choices_k = [0.7, 0.9]  # kappa values for female and male\n",
    "choices_alpha = [-0.241, -0.302]  # alpha values for female and male\n",
    "X_test['kappa'] = np.select(conditions, choices_k, default=np.nan)\n",
    "X_test['alpha'] = np.select(conditions, choices_alpha, default=np.nan)\n",
    "\n",
    "# Calculate eGFR using the CKD-EPI 2021 equation\n",
    "X_test['eGFR'] = 142 * (X_test['Cr_mg_dL'] / X_test['kappa']).clip(upper=1)**X_test['alpha'] * \\\n",
    "                        (X_test['Cr_mg_dL'] / X_test['kappa']).clip(lower=1)**(-1.2) * \\\n",
    "                        0.9938**X_test['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Code the KFRE\n",
    "- Tangri N, Grams ME, Levey AS, Coresh J, Appel LJ, Astor BC, et al. Multinational Assessment of Accuracy of Equations for Predicting Risk of Kidney Failure: A Meta-analysis. JAMA. 2016;315(2): 164–174. https://doi.org/10.1001/jama.2015.18202.\n",
    "\n",
    "#### 4-variable 2-yr calibrated non-American equation\n",
    "- 1 - 0.9832^exp(-0.2201 x (age/10 – 7.036) + 0.2467 x (male – 0.5642) – 0.5567 x (eGFR/5 – 7.222) + 0.4510 x (logACR – 5.137))\n",
    "#### 8-variable 2-yr calibrated non-American equation\n",
    "- 1 – 0.9827 ^ exp (-0.1992 × (age/10 – 7.036) + 0.1602 × (male – 0.5642) – 0.4919 × (eGFR/5 – 7.222) + 0.3364 × (logACR – 5.137) – 0.3441 × (albumin – 3.997) + 0.2604 × (phosphorous – 3.916) – 0.07354 × (bicarbonate – 25.57) – 0.2228 × (calcium – 9.355))\n",
    "#### 4-variable 5-yr calibrated non-American equation\n",
    "- 1 – 0.9365 ^ exp (-0.2201 × (age/10 – 7.036) + 0.2467 × (male – 0.5642) – 0.5567 × (eGFR/5 – 7.222) + 0.4510 × (logACR – 5.137))\n",
    "#### 8-variable 5-yr calibrated non-American equation\n",
    "- 1 – 0.9245 ^ exp (-0.1992 × (age/10 – 7.036) + 0.1602 × (male – 0.5642) – 0.4919 × (eGFR/5 – 7.222) + 0.3364 × (logACR – 5.137) – 0.3441 × (albumin – 3.997) + 0.2604 × (phosphorous – 3.916) – 0.07354 × (bicarbonate – 25.57) – 0.2228 × (calcium – 9.355))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define risk calculation functions\n",
    "def calculate_4_variable_2yr_risk(row):\n",
    "    return 1 - 0.9832**np.exp(-0.2201 * (row['age'] / 10 - 7.036) + \n",
    "                              0.2467 * (row['gender'] - 0.5642) - \n",
    "                              0.5567 * (row['eGFR'] / 5 - 7.222) + \n",
    "                              0.4510 * (np.log(row['UACR_mg_g']) - 5.137))\n",
    "\n",
    "def calculate_8_variable_2yr_risk(row):\n",
    "    return 1 - 0.9827**np.exp(-0.1992 * (row['age'] / 10 - 7.036) + \n",
    "                              0.1602 * (row['gender'] - 0.5642) - \n",
    "                              0.4919 * (row['eGFR'] / 5 - 7.222) + \n",
    "                              0.3364 * (np.log(row['UACR_mg_g']) - 5.137) - \n",
    "                              0.3441 * (row['alb'] - 3.997) + \n",
    "                              0.2604 * (row['po4'] - 3.916) - \n",
    "                              0.07354 * (row['hco3'] - 25.57) - \n",
    "                              0.2228 * (row['ca'] - 9.355))\n",
    "\n",
    "def calculate_4_variable_5yr_risk(row):\n",
    "    return 1 - 0.9365**np.exp(-0.2201 * (row['age'] / 10 - 7.036) + \n",
    "                              0.2467 * (row['gender'] - 0.5642) - \n",
    "                              0.5567 * (row['eGFR'] / 5 - 7.222) + \n",
    "                              0.4510 * (np.log(row['UACR_mg_g']) - 5.137))\n",
    "\n",
    "def calculate_8_variable_5yr_risk(row):\n",
    "    return 1 - 0.9245**np.exp(-0.1992 * (row['age'] / 10 - 7.036) + \n",
    "                              0.1602 * (row['gender'] - 0.5642) - \n",
    "                              0.4919 * (row['eGFR'] / 5 - 7.222) + \n",
    "                              0.3364 * (np.log(row['UACR_mg_g']) - 5.137) - \n",
    "                              0.3441 * (row['alb'] - 3.997) + \n",
    "                              0.2604 * (row['po4'] - 3.916) - \n",
    "                              0.07354 * (row['hco3'] - 25.57) - \n",
    "                              0.2228 * (row['ca'] - 9.355))\n",
    "    \n",
    "pred_df = pd.DataFrame(index=X_test.index)\n",
    "pred_df['4v2y'] = X_test.apply(calculate_4_variable_2yr_risk, axis=1) \n",
    "pred_df['8v2y'] = X_test.apply(calculate_8_variable_2yr_risk, axis=1) \n",
    "pred_df['4v5y'] = X_test.apply(calculate_4_variable_5yr_risk, axis=1) \n",
    "pred_df['8v5y'] = X_test.apply(calculate_8_variable_5yr_risk, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for time in np.array([2*365, 5*365]):\n",
    "    for c in pred_df.columns:\n",
    "        prob_df = pd.DataFrame({\n",
    "            'predicted_probs': pred_df[c].values,\n",
    "            'observed_probs': np.nan  # Placeholder for observed probabilities\n",
    "        }, index=y_test.index)\n",
    "        prob_df['quantile'] = pd.qcut(prob_df['predicted_probs'], 5, labels=False, duplicates='drop')\n",
    "        prob_df['quantile'] = prob_df['quantile'].astype(int)\n",
    "        # Calculate observed probabilities for each quintile using Aalen-Johansen estimator\n",
    "        observed_probs = []\n",
    "        for q in prob_df['quantile'].unique():\n",
    "            mask = prob_df['quantile'] == q\n",
    "            durations = pd.Series(y_test.loc[mask, duration_col[0]].values.ravel(), index=y_test.loc[mask, duration_col[0]].index).astype(float)\n",
    "            event_observed = pd.Series(y_test.loc[mask, event_col[0]].values.ravel(), index=y_test.loc[mask, event_col[0]].index)\n",
    "            ajf = AalenJohansenFitter()\n",
    "            ajf.fit(durations=durations, event_observed=event_observed, event_of_interest=1)\n",
    "            # Find the closest time point if `time` is not in the index\n",
    "            if time not in ajf.cumulative_density_.index:\n",
    "                closest_idx = ajf.cumulative_density_.index.get_indexer([time], method='nearest')[0]\n",
    "                closest_time = ajf.cumulative_density_.index[closest_idx]\n",
    "            else:\n",
    "                closest_time = time\n",
    "            observed_probs.append(ajf.cumulative_density_.loc[closest_time].values[0])\n",
    "        # Map observed probabilities back to the DataFrame\n",
    "        prob_df['observed_probs'] = prob_df['quantile'].map(dict(zip(prob_df['quantile'].unique(), observed_probs)))\n",
    "        grouped = prob_df.groupby('quantile')\n",
    "        observed_events = grouped['observed_probs'].mean()\n",
    "        expected_events = grouped['predicted_probs'].mean()\n",
    "        # mean_p_g = grouped['predicted_probs'].mean()\n",
    "        n = grouped.size()\n",
    "            \n",
    "        # chi2_stat = np.sum(((observed_events - expected_events) ** 2) / (n * mean_p_g * (1 - mean_p_g)))\n",
    "        chi2_stat = np.sum(((observed_events - expected_events) ** 2) / (expected_events * (1 - expected_events/ n)))\n",
    "        dof = len(n) - 2\n",
    "        # Calculate p-value\n",
    "        p_value = 1 - chi2.cdf(chi2_stat, dof)\n",
    "        print(f'Time: {time} - Column: {c} - Chi-squared Statistic: {chi2_stat}')\n",
    "        \n",
    "        # Calculate Brier score\n",
    "        brier_score = brier_score_loss(y_test[event_col[0]], prob_df['predicted_probs'])\n",
    "\n",
    "        # Calculate Concordance Index (C-index)\n",
    "        c_index = concordance_index(y_test[duration_col[0]], -prob_df['predicted_probs'], y_test[event_col[0]])\n",
    "\n",
    "        # Store the result\n",
    "        results.append({\n",
    "            'time': time,\n",
    "            'column': c,\n",
    "            'observed_events': observed_events,\n",
    "            'expected events': expected_events,\n",
    "            'chi2_stat': chi2_stat,\n",
    "            'p-value': p_value,\n",
    "            'brier_score': brier_score,\n",
    "            'c_index': c_index\n",
    "        })\n",
    "        \n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_json('/mnt/d/pydatascience/g3_regress/data/results/kfre.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bootstrap 500 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_null_brier(durations, events, time_grid, event_of_interest=1):\n",
    "    \"\"\"\n",
    "    Calculate the null model Brier score for a given set of durations and events.\n",
    "\n",
    "    Args:\n",
    "        durations (array-like): Event/censoring times.\n",
    "        events (array-like): Event indicators (1 for event, 0 for censoring).\n",
    "        time_grid (list): List of time points for evaluation.\n",
    "        event_of_interest (int): The event type of interest for competing risks.\n",
    "\n",
    "    Returns:\n",
    "        float: Integrated Brier score for the null model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def interpolate_cif(cif, time_points):\n",
    "        cif_values = cif.values.squeeze()\n",
    "        cif_index = cif.index.values\n",
    "        max_time = cif_index[-1]\n",
    "        max_cif_value = cif_values[-1]\n",
    "        \n",
    "        # Interpolation within range\n",
    "        interpolated = np.interp(time_points, cif_index, cif_values)\n",
    "        \n",
    "        # Handle extrapolation for times > max_time\n",
    "        interpolated[time_points > max_time] = max_cif_value\n",
    "        \n",
    "        return interpolated\n",
    "    # Ensure durations and events are NumPy arrays\n",
    "    durations = durations.squeeze()\n",
    "    events = events.squeeze()\n",
    "    \n",
    "    # # Resolve ties in event times by adding small noise\n",
    "    # unique_durations, counts = np.unique(durations, return_counts=True)\n",
    "    # tied_indices = np.isin(durations, unique_durations[counts > 1])\n",
    "    # noise = np.random.uniform(low=-1e-6, high=1e-6, size=len(durations))\n",
    "    # durations[tied_indices] += noise[tied_indices]\n",
    "\n",
    "    # Fit Aalen-Johansen estimator\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(durations, events)\n",
    "    cif = kmf.cumulative_density_\n",
    "    \n",
    "    # Calculate survival probabilities\n",
    "    surv_probs = 1 - interpolate_cif(cif, time_grid) \n",
    "    # Create survival probability DataFrame for EvalSurv\n",
    "    surv_df = pd.DataFrame(\n",
    "        np.tile(surv_probs, (len(durations), 1)).T, index=time_grid\n",
    "    )\n",
    "\n",
    "    # Evaluate using EvalSurv\n",
    "    ev = EvalSurv(surv_df, durations, events == event_of_interest, censor_surv=\"km\")\n",
    "\n",
    "    # Integrated Brier score\n",
    "    brier = ev.brier_score(time_grid)\n",
    "    return brier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_results = []\n",
    "# Initialize storage for bootstrapped results\n",
    "null_brier_scores = {}\n",
    "# Number of bootstraps\n",
    "n_bootstraps = 500\n",
    "\n",
    "for i in range(n_bootstraps):\n",
    "    print(f'On {i+1}th bootstrap:')\n",
    "    # Resample with replacement\n",
    "    X_test_bootstrap = X_test[X_test.index.isin(resample(X_test.index))]\n",
    "    y_test_bootstrap = y_test.iloc[X_test_bootstrap.index,:]\n",
    "    \n",
    "    # Calculate KFRE risks\n",
    "    pred_df = pd.DataFrame(index=X_test_bootstrap.index)\n",
    "    pred_df['4v2y'] = X_test_bootstrap.apply(calculate_4_variable_2yr_risk, axis=1)\n",
    "    pred_df['8v2y'] = X_test_bootstrap.apply(calculate_8_variable_2yr_risk, axis=1)\n",
    "    pred_df['4v5y'] = X_test_bootstrap.apply(calculate_4_variable_5yr_risk, axis=1)\n",
    "    pred_df['8v5y'] = X_test_bootstrap.apply(calculate_8_variable_5yr_risk, axis=1)\n",
    "    \n",
    "# Calculate null Brier scores for each time grid\n",
    "    null_brier_scores[i] = calculate_null_brier(\n",
    "            y_test_bootstrap[duration_col].values,\n",
    "            y_test_bootstrap[event_col].values,\n",
    "            np.array([730, 1825])\n",
    "            )    \n",
    "    \n",
    "    for time in np.array([2 * 365, 5 * 365]):\n",
    "        for c in pred_df.columns:\n",
    "            prob_df = pd.DataFrame({\n",
    "                'predicted_probs': pred_df[c].values,\n",
    "                'observed_probs': np.nan  # Placeholder for observed probabilities\n",
    "            }, index=y_test_bootstrap.index)\n",
    "            prob_df['quantile'] = pd.qcut(prob_df['predicted_probs'], 5, labels=False, duplicates='drop')\n",
    "            prob_df['quantile'] = prob_df['quantile'].astype(int)\n",
    "                \n",
    "            observed_probs = []\n",
    "            for q in prob_df['quantile'].unique():\n",
    "                mask = prob_df['quantile'] == q\n",
    "                durations = y_test_bootstrap.loc[mask, duration_col[0]].astype(float)\n",
    "                event_observed = y_test_bootstrap.loc[mask, event_col[0]]\n",
    "                kmf = KaplanMeierFitter()\n",
    "                kmf.fit(durations=durations, event_observed=event_observed)\n",
    "                \n",
    "                if time not in kmf.cumulative_density_.index:\n",
    "                    closest_idx = kmf.cumulative_density_.index.get_indexer([time], method='nearest')[0]\n",
    "                    closest_time = kmf.cumulative_density_.index[closest_idx]\n",
    "                else:\n",
    "                    closest_time = time\n",
    "                observed_probs.append(kmf.cumulative_density_.loc[closest_time].values[0]) \n",
    "                \n",
    "            prob_df['observed_probs'] = prob_df['quantile'].map(dict(zip(prob_df['quantile'].unique(), observed_probs)))\n",
    "            grouped = prob_df.groupby('quantile')\n",
    "            observed_events = grouped['observed_probs'].mean()\n",
    "            expected_events = grouped['predicted_probs'].mean()\n",
    "            n = grouped.size()        \n",
    "            \n",
    "        \n",
    "            chi2_stat = np.sum(((observed_events - expected_events) ** 2) / (expected_events * (1 - expected_events / n)))\n",
    "            dof = len(n) - 2\n",
    "            p_value = 1 - chi2.cdf(chi2_stat, dof)\n",
    "            brier_score = brier_score_loss(y_test_bootstrap[event_col[0]], prob_df['predicted_probs'])\n",
    "            c_index = concordance_index(y_test_bootstrap[duration_col[0]], -prob_df['predicted_probs'], y_test_bootstrap[event_col[0]])\n",
    "\n",
    "            # Store bootstrap result\n",
    "            bootstrap_results.append({\n",
    "                'time': time,\n",
    "                'column': c,\n",
    "                'brier_score': brier_score,\n",
    "                'c_index': c_index,\n",
    "                'chi2_stat': chi2_stat,\n",
    "                'p_value': p_value,\n",
    "                'null_brier_score': null_brier_scores[i][time]\n",
    "            })        \n",
    "    print('done.')    \n",
    "bootstrap_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>column</th>\n",
       "      <th>brier_score</th>\n",
       "      <th>c_index</th>\n",
       "      <th>chi2_stat</th>\n",
       "      <th>p_value</th>\n",
       "      <th>null_brier_score</th>\n",
       "      <th>ipa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>4v2y</td>\n",
       "      <td>0.048469</td>\n",
       "      <td>0.971367</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.934056</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>-6.228347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>730</td>\n",
       "      <td>8v2y</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.916835</td>\n",
       "      <td>7.331363</td>\n",
       "      <td>0.062054</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>0.275380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>4v5y</td>\n",
       "      <td>0.132135</td>\n",
       "      <td>0.971367</td>\n",
       "      <td>0.937856</td>\n",
       "      <td>0.816284</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>-18.705524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>730</td>\n",
       "      <td>8v5y</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.916835</td>\n",
       "      <td>1.604843</td>\n",
       "      <td>0.658292</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>0.270165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1825</td>\n",
       "      <td>4v2y</td>\n",
       "      <td>0.048469</td>\n",
       "      <td>0.971367</td>\n",
       "      <td>0.821696</td>\n",
       "      <td>0.844271</td>\n",
       "      <td>0.558042</td>\n",
       "      <td>0.913144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>730</td>\n",
       "      <td>8v5y</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.917804</td>\n",
       "      <td>3.292793</td>\n",
       "      <td>0.348647</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.312352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>1825</td>\n",
       "      <td>4v2y</td>\n",
       "      <td>0.048540</td>\n",
       "      <td>0.971491</td>\n",
       "      <td>0.165013</td>\n",
       "      <td>0.983029</td>\n",
       "      <td>0.889770</td>\n",
       "      <td>0.945446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>1825</td>\n",
       "      <td>8v2y</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.917804</td>\n",
       "      <td>2804.776810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.889770</td>\n",
       "      <td>0.994334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>1825</td>\n",
       "      <td>4v5y</td>\n",
       "      <td>0.131707</td>\n",
       "      <td>0.971491</td>\n",
       "      <td>0.624625</td>\n",
       "      <td>0.890773</td>\n",
       "      <td>0.889770</td>\n",
       "      <td>0.851976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>1825</td>\n",
       "      <td>8v5y</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.917804</td>\n",
       "      <td>624.272032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.889770</td>\n",
       "      <td>0.994298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time column  brier_score   c_index    chi2_stat   p_value  \\\n",
       "0      730   4v2y     0.048469  0.971367     0.429630  0.934056   \n",
       "1      730   8v2y     0.004859  0.916835     7.331363  0.062054   \n",
       "2      730   4v5y     0.132135  0.971367     0.937856  0.816284   \n",
       "3      730   8v5y     0.004894  0.916835     1.604843  0.658292   \n",
       "4     1825   4v2y     0.048469  0.971367     0.821696  0.844271   \n",
       "...    ...    ...          ...       ...          ...       ...   \n",
       "3995   730   8v5y     0.005073  0.917804     3.292793  0.348647   \n",
       "3996  1825   4v2y     0.048540  0.971491     0.165013  0.983029   \n",
       "3997  1825   8v2y     0.005042  0.917804  2804.776810  0.000000   \n",
       "3998  1825   4v5y     0.131707  0.971491     0.624625  0.890773   \n",
       "3999  1825   8v5y     0.005073  0.917804   624.272032  0.000000   \n",
       "\n",
       "      null_brier_score        ipa  \n",
       "0             0.006705  -6.228347  \n",
       "1             0.006705   0.275380  \n",
       "2             0.006705 -18.705524  \n",
       "3             0.006705   0.270165  \n",
       "4             0.558042   0.913144  \n",
       "...                ...        ...  \n",
       "3995          0.007378   0.312352  \n",
       "3996          0.889770   0.945446  \n",
       "3997          0.889770   0.994334  \n",
       "3998          0.889770   0.851976  \n",
       "3999          0.889770   0.994298  \n",
       "\n",
       "[4000 rows x 8 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_df = pd.DataFrame(bootstrap_results)\n",
    "bootstrap_df.loc[bootstrap_df['null_brier_score'] == 0, 'null_brier_score'] = np.nan\n",
    "bootstrap_df['null_brier_score'] = bootstrap_df['null_brier_score'].fillna(1e-7)\n",
    "bootstrap_df['ipa'] = 1 - (bootstrap_df['brier_score']/bootstrap_df['null_brier_score'])\n",
    "# Aggregate metrics\n",
    "summary = bootstrap_df.groupby(['time', 'column']).agg(\n",
    "    mean_brier=('brier_score', 'mean'),\n",
    "    ci_lower_brier=('brier_score', lambda x: np.percentile(x, 2.5)),\n",
    "    ci_upper_brier=('brier_score', lambda x: np.percentile(x, 97.5)),\n",
    "    mean_c_index=('c_index', 'mean'),\n",
    "    ci_lower_c_index=('c_index', lambda x: np.percentile(x, 2.5)),\n",
    "    ci_upper_c_index=('c_index', lambda x: np.percentile(x, 97.5)),\n",
    "    mean_chi2=('chi2_stat', 'mean'),\n",
    "    mean_p_value=('p_value', 'mean'),\n",
    "    mean_ipa=('ipa', 'mean'),\n",
    "    ci_lower_ipa=('ipa', lambda x: np.percentile(x, 2.5)),\n",
    "    ci_upper_ipa=('ipa', lambda x: np.percentile(x, 97.5)),\n",
    ").reset_index()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = summary.loc[[0,2,5,7], :]\n",
    "final_df.to_json('/mnt/d/pydatascience/g3_regress/data/results/kfre_bootstrap.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
